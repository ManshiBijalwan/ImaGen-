from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession
import tensorflow as tf
config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)
from google.colab import drive
drive.mount('/content/drive')
import tensorflow as tf
from tqdm import tqdm
import cv2
import skimage.io as io
from glob import glob
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import statistics
import random
import time
from tqdm import tqdm
import keras

from keras.optimizers import Adam, RMSprop
from keras.initializers import RandomNormal, RandomUniform
from keras.models import Model
from keras import Input
from keras.layers import Conv2D
from keras.layers import LeakyReLU
from keras.layers import Activation
from keras.layers import Concatenate
from keras.layers import BatchNormalization
from keras.utils  import plot_model

def crop(img, size=512):
    x,y = img.shape[0],img.shape[1]
    x1 = random.randrange(0, max(1, x - 2*size))
    y1 = random.randrange(0, max(1, y - 2*size))
    img1 = img[x1:x1+2*size,y1:y1+2*size]
    img1 = cv2.resize(img1, (size,size))
    return img1
    #this piece of code is writen to crop the images, for pixel 512

t1=time.time()
plt.figure(num=None, figsize=(10, 10), dpi=50, facecolor='w', edgecolor='k')
t = tqdm(range(9)) #we have taken 9 images and plot them into 3by 3 grid
for i in t:
    img = cv2.imread(ls[i],0)
    img = crop(img)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    #cv2.imshow('img1', img1)
    #cv2.imshow('img', img)
    #cv2.waitKey()
    #cv2.destroyAllWindows()
    plt.subplot(331+i)
    plt.imshow(img[:,:,:])
t2=time.time()
t2-t1
# this piece is basically going to visualize the images in the dataset, it is converted into grey

t = tqdm(range(9), desc='ML')
t1=time.time()
plt.figure(num=None, figsize=(10, 10), dpi=50, facecolor='w', edgecolor='k')
size = 1024
for i in t:
    img = cv2.imread(ls[i],1)
    img = crop(img,1024)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    #cv2.imshow('img1', img1)
    #cv2.imshow('img', img)
    #cv2.waitKey()
    #cv2.destroyAllWindows()
    plt.subplot(331+i)
    plt.imshow(img[:,:,:])
t2=time.time()
t2-t1 #this piece of code colouroizes the dataset, we can see the type of images in dataset


# define the discriminator model
def define_discriminator(g_image_shape, d_image_shape):
    # weight initialization
    init = RandomNormal(stddev=0.02)
    # source image input
    in_src_image = Input(shape=g_image_shape)
    # target image input
    in_target_image = Input(shape=d_image_shape)
    # concatenate images channel-wise
    merged = Concatenate()([in_src_image, in_target_image])
    # C64 this the number of blocks, as they increase the size of image decreases.
    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)
    d = LeakyReLU(alpha=0.2)(d)
    # C128
    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
    d = BatchNormalization()(d)
    d = LeakyReLU(alpha=0.2)(d)
    # C256
    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
    d = BatchNormalization()(d)
    d = LeakyReLU(alpha=0.2)(d)
    # C512
    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
    d = BatchNormalization()(d)
    d = LeakyReLU(alpha=0.2)(d)
    # C1024
    d = Conv2D(1024, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
    d = BatchNormalization()(d)
    d = LeakyReLU(alpha=0.2)(d)
    # second last output layer
    d = Conv2D(1024, (4,4), padding='same', kernel_initializer=init)(d)
    d = BatchNormalization()(d)
    d = LeakyReLU(alpha=0.2)(d)
    # patch output
    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)
    patch_out = Activation('sigmoid')(d)
    # define model
    model = Model([in_src_image, in_target_image], patch_out)
    # compile model
    opt = Adam(learning_rate=0.0002, beta_1=0.5)#gradient is multiplied by lr
    model.compile(loss='binary_crossentropy', optimizer=opt,)
    return model

# define image shape
g_image_shape = (512,512,1)
d_image_shape = (512,512,2)
# create the model
model = define_discriminator(g_image_shape, d_image_shape)
# summarize the model
model.summary()
# plot the model
plot_model(model, to_file='discriminator_model_plot.png', show_shapes=True, show_layer_names=True)

# example of defining a u-net encoder-decoder generator model
# we tested on the above two codes and we found out that this code is better, skip connection is the difference, we add connection between first and last layer for easy infor gathering
from keras.initializers import RandomNormal
from keras.models import Model
from keras import Input
from keras.layers import Conv2D
from keras.layers import Conv2DTranspose
from keras.layers import LeakyReLU
from keras.layers import Activation
from keras.layers import Concatenate
from keras.layers import Dropout
from keras.layers import BatchNormalization
from keras.layers import LeakyReLU
from keras.utils import plot_model

# define an encoder block
def define_encoder_block(layer_in, n_filters, batchnorm=True):
    # weight initialization
    init = RandomNormal(stddev=0.02)
    # add downsampling layer
    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)
    # conditionally add batch normalization
    if batchnorm:
        g = BatchNormalization()(g, training=True)
    # leaky relu activation
    g = LeakyReLU(alpha=0.2)(g)
    return g

# define a decoder block
def decoder_block(layer_in, skip_in, n_filters, dropout=True):
    # weight initialization
    init = RandomNormal(stddev=0.02)
    # add upsampling layer
    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)
    # add batch normalization
    g = BatchNormalization()(g, training=True)
    # conditionally add dropout
    if dropout:
        g = Dropout(0.5)(g, training=True)
    # merge with skip connection
    g = Concatenate()([g, skip_in])
    # relu activation
    g = Activation('relu')(g)
    return g

# define the standalone generator model
def define_generator(image_shape):
    # weight initialization
    init = RandomNormal(stddev=0.02)
    # image input
    in_image = Input(shape=image_shape)
    # encoder model: C64-C128-C256-C512-C512-C512-C512-C512-C512
    e1 = define_encoder_block(in_image, 64, batchnorm=False)
    e2 = define_encoder_block(e1, 128)
    e3 = define_encoder_block(e2, 256)
    e4 = define_encoder_block(e3, 512)
    e5 = define_encoder_block(e4, 512)
    e6 = define_encoder_block(e5, 512)
    e7 = define_encoder_block(e6, 512)
    e8 = define_encoder_block(e7, 512)
    # bottleneck, no batch norm and relu
    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e8)
    b = Activation('relu')(b)
    # decoder model: CD512-CD1024-CD1024-CD1024-C1024-C1024-C512-C256-C128
    d0 = decoder_block(b, e8, 512)
    d1 = decoder_block(d0, e7, 512)
    d2 = decoder_block(d1, e6, 512)
    d3 = decoder_block(d2, e5, 512)
    d4 = decoder_block(d3, e4, 512, dropout=False)
    d5 = decoder_block(d4, e3, 256, dropout=False)
    d6 = decoder_block(d5, e2, 128, dropout=False)
    d7 = decoder_block(d6, e1, 64, dropout=False)
    # output
    g = Conv2DTranspose(2, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)
    out_image = Activation('tanh')(g)
    # define model
    model = Model(in_image, out_image)
    return model

# define image shape
image_shape = (512,512,1)
# create the model
model = define_generator(image_shape)
# summarize the model
model.summary()
# plot the model
plot_model(model, to_file='generator_model_plot.png', show_shapes=True, show_layer_names=True)


#combination of generator and discriminator
def define_gan(g_model, d_model, g_image_shape, d_image_shape):
    # make weights in the discriminator not trainable
    d_model.trainable = False
    # define the source image
    in_src = Input(shape=g_image_shape)
    # connect the source image to the generator input
    gen_out = g_model(in_src)
    # connect the source input and generator output to the discriminator input
    dis_out = d_model([in_src, gen_out])
    # src image as input, generated image and classification output
    model = Model(in_src, [dis_out, gen_out])
    # compile model
    opt = Adam(learning_rate=0.0002, beta_1=0.5)
    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])
    return model

# define image shape
g_image_shape = (512,512,1)
d_image_shape = (512,512,2)
# define the models
d_model = define_discriminator(g_image_shape, d_image_shape)
opt = Adam(learning_rate=0.0002, beta_1=0.5)
d_model.compile(loss='binary_crossentropy', optimizer=opt,)
g_model = define_generator(g_image_shape)

# define the composite model
gan_model = define_gan(g_model, d_model, g_image_shape, d_image_shape)
# summarize the model
gan_model.summary()
# plot the model
plot_model(gan_model, to_file='gan_model_plot.png', show_shapes=True, show_layer_names=True)

# select a batch of random samples, returns images and target, gives random batches of images
def generate_real_samples(ls, n_samples, patch_shape):
    # unpack dataset
    X1, X2 = np.zeros((n_samples,512,512,1), dtype = 'float64'), np.zeros((n_samples,512,512,2), dtype = 'float64')
    img_ran = random.sample(range(0, len(ls)), n_samples)
    for i in range(n_samples):
        img_name = ls[img_ran[i]]
        img = cv2.imread(img_name)
        img = crop(img)
        #print("Real_image",img.max(), img.min())
        img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)
        X1[i,:,:,:] = img_lab[:,:,0:1]
        X2[i,:,:,:] = img_lab[:,:,1:]
    X1 = X1/127.5 -1
    X2 = X2/127.5 -1
    y = np.ones((n_samples, patch_shape, patch_shape, 1))
    return [X1, X2], y


# generate a batch of images, returns images and targets, generates colourized images from generator
def generate_fake_samples(g_model, samples, patch_shape):
    # generate fake instance
    X = g_model.predict(samples)
    # create 'fake' class labels (0)
    y = np.zeros((len(X), patch_shape, patch_shape, 1))
    return X, y

#this code is used to test the performance of the model
def summarize_performance(step, g_model, d_model, ls, n_patch, n_batch=3):
    # select a sample of input images
    [X_realA, X_realB], _ = generate_real_samples(ls, n_batch, n_patch)
    # generate a batch of fake samples
    X_fakeB, _ = generate_fake_samples(g_model, X_realA, n_patch)
    # scale all pixels from [-1,1] to [0,1]
    X_realA = (X_realA + 1) * 127.5
    X_realB = (X_realB + 1) * 127.5
    X_fakeB = (X_fakeB + 1) * 127.5

    X_realA = np.array(X_realA, dtype='uint8')
    X_realB = np.array(X_realB, dtype='uint8')
    X_fakeB = np.array(X_fakeB, dtype='uint8')

    # plot real source images
    plt.figure(figsize=(15,15), dpi=70, constrained_layout=True)
    n_samples = 3
    for i in range(n_samples):
        plt.subplot(3, n_samples, 1 + i)
        plt.axis('off')
        plt.imshow(X_realA[i,:,:,0], cmap='gray')

    # plot generated target image
    for i in range(n_samples):
        plt.subplot(3, n_samples, 1 + n_samples + i)
        plt.axis('off')
        img = np.concatenate((X_realA[i],X_realB[i]), axis=2)
        img = cv2.cvtColor(img, cv2.COLOR_Lab2RGB)
        plt.imshow(img)

    # plot real target image
    for i in range(n_samples):
        plt.subplot(3, n_samples, 1 + n_samples*2 + i)
        plt.axis('off')
        img = np.concatenate((X_realA[i],X_fakeB[i]), axis=2)
        img = cv2.cvtColor(img, cv2.COLOR_Lab2RGB)
        plt.imshow(img)

    # save plot to file
    import os
    os.makedirs('/content/drive/MyDrive/archive/plot_unet', exist_ok=True)#it will create folder/directory
    filename1 = '/content/drive/MyDrive/archive/plot_unet/plot_%02d.png' % (step)
    plt.savefig(filename1)
    plt.close()
    # save the generator model
    if (step)%5000==0:
        filename_gan = '/content/drive/MyDrive/archive/model_unet_gan/model_%02d.h5' % (step)
        filename_dis = '/content/drive/MyDrive/archive/model_unet_dis/model_%02d.h5' % (step)
        g_model.save(filename_gan)
        d_model.save(filename_dis)
        #print('>Saved: %s' % (filename2))
    #print('>Saved: %s' % (filename1))
# train pix2pix models
#this is main training loop and above is a helper function. This code used the functions used above.
def train(d_model, g_model, gan_model, ls, start, n_epochs=100, n_batch=1, n_patch=16):
    # calculate the number of batches per training epoch
    bat_per_epo = int(len(ls) / n_batch)
    # calculate the number of training iterations
    n_steps = 100000
    # manually enumerate epochs
    t = tqdm(range(n_steps), desc='ML')
    sample_interval=200

    for i in t:
        # select a batch of real samples
        [X_realA, X_realB], y_real = generate_real_samples(ls, n_batch, n_patch)
        # generate a batch of fake samples
        X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)
        # update discriminator for real samples
        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)
        # update discriminator for generated samples
        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)
        # update the generator
        g_loss, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])
        # summarize performance
        #print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))
        #print(i+1, d_loss1, d_loss2, g_loss)
        t.set_description('>%d, d1[%.4f] d2[%.4f] g[%.4f]' % (i+1, d_loss1, d_loss2, g_loss))

        if i%2==0:
            d_model.trainable=True
            g_model.trainable=False
            #print("D_model = True, G_model = False");
            #we cannot train discriminator and generator model together because it hinders conversion, hence this loop stops one model at the time to train another one.

        elif i%1==0:
            d_model.trainable=False
            g_model.trainable=True
            #print("D_model = False, G_model = True");

        if (start+i) % (sample_interval) == 0:
            summarize_performance(start+i, g_model, d_model,ls, n_patch)

